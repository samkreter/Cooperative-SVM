\documentclass[journal]{IEEEtran}

\ifCLASSINFOpdf
\else
\fi

\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Implementing an SVM\\ A shot in the dark}

\author{Daniel Hanson, Sam Kreter, Brendan Marsh, and Christina R.S. Mosnick}

\markboth{ECE/CS 4720 (Spring 2016): Introduction to Machine Learning and Pattern Recognition}
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

\maketitle

\begin{abstract}
The abstract goes here.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

\IEEEPARstart{O}{ur} introduction paragraph goes here. This is just some sample text to fill up the space.

%\hfill mds

%\hfill August 26, 2015

\subsection{Subsection \#1}
Subsection text here. Sample text and stuff goes here.

\section{Implementation}
    \subsection{Dual Representation (from Eqn. 7.2 \cite{BishopBook})}
    \begin{equation}
    \mathbf{L} = \sum\limits_{N} a_n - \frac{1}{2} \sum\limits_{n} \sum\limits_{m} a_n a_m t_n t_m \mathbf{K}
    \end{equation}

    \subsection{Quadratic Programming Problem \cite{QuadraticCVXOPT}}
    \begin{equation}
    \min_{\mathbf{x}} \frac{1}{2}\mathbf{x}^T\mathbf{P}\mathbf{x} - \mathbf{Q}^T\mathbf{x}
    \end{equation}

    \subsection{Parameters for Quadratic Programming}
    \begin{eqnarray}
    P = \sum\limits_{n} \sum\limits_{m} t_n t_m \mathbf{K}\\
    Q = \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    -1&-1&-1\\
    -1&-1&-1\\
    -1&-1&-1%
    \end{IEEEeqnarraybox*}\right)
    \end{eqnarray}
    \begin{itemize}
    \item Where Q's dimensions are determined by number of samples
    \end{itemize}

    \subsection{Constraints}
    \begin{equation}
    \mathbf{G} \mathbf{x} \preceq \mathbf{h}
    \end{equation}

    \begin{equation}
    a_n \geq 0 \rightarrow -a_n \leq 0
    \end{equation}

    \begin{equation}
    a_n \leq \mathbf{C}
    \end{equation}

    \begin{equation}
    std\mathbf{G} \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    -1&0&0\\
    0&-1&0\\
    0&0&-1%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}

    \begin{equation}
    std\mathbf{H} \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    0&0&0\\
    0&0&0\\
    0&0&0%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}

    \begin{equation}
    slack\mathbf{G} \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    1&0&0\\
    0&1&0\\
    0&0&1%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}

    \begin{equation}
    slack\mathbf{H} \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    \mathbf{C}&\mathbf{C}&\mathbf{C}\\
    \mathbf{C}&\mathbf{C}&\mathbf{C}\\
    \mathbf{C}&\mathbf{C}&\mathbf{C}%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}

    \begin{equation}
    \mathbf{A} \mathbf{x} \leq \mathbf{b}
    \end{equation}

    \begin{equation}
    \sum\limits_{n = 1}^Na_n t_n = 0
    \end{equation}

    \begin{equation}
    \mathbf{A} = \mathbf{y} \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    1&1&1\\
    1&1&1\\
    1&1&1%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}

    \begin{equation}
    \mathbf{B} = \left(\begin{IEEEeqnarraybox*}[][c]{,c/c/c,}
    0&0&0\\
    0&0&0\\
    0&0&0%
    \end{IEEEeqnarraybox*}\right)
    \end{equation}



\section{Experiments}

After the SVMs were all trained using the bootstrapping method, we used a committee-waterfall approach to determine the best class for each test point.  In order to do this, the SVMs are grouped by classifier, with 7 independently trained SVMs per each of the 8 classifiers.  Each test point is run through each of the 7*8=56 SVMs.  When committee results are gathered, if the point has less than 4 committee votes for each classifier, it is unclassified.  If the point has 4 or more votes from just one classifier group, it is classified to that group. If the point has 4 or more votes from multiple classification committees, it is classified to the committee with the most votes, or in the event of a tie, to a random choice between the tie.

\section{Conclusion}
Conclusion paragraph text goes here.

\section*{Acknowledgment}

Christina would like to thank her mom for her support.

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\begin{thebibliography}{1}

\bibitem{BishopBook}
  Bishop, Christopher M. \emph{Pattern Recognition And Machine Learning.} New York: Springer, 2006. Print.

\bibitem{TullochSVMpy}
  Tulloch, Andrew. \emph{A Basic Soft-Margin Kernel SVM Implementation In Python} Tullo.ch. N.p., 2013. Web. 24 Mar. 2016.

\bibitem{QuadraticCVXOPT}
  \emph{Quadratic Programming With Python And CVXOPT. N.p., 2016. Web. 24 Mar. 2016.}

\bibitem{EffectiveNumpy}
  \emph{How To Calculate A Gaussian Kernel Effectively In Numpy.} Stats.stackexchange.com. N.p., 2016. Web. 24 Mar. 2016.

\bibitem{Pdist}
  \emph{Scipy.Spatial.Distance.Pdist â€” Scipy V0.17.0 Reference Guide.} Docs.scipy.org. N.p., 2016. Web. 24 Mar. 2016.

\end{thebibliography}

\end{document}